{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to complete the assignment I use the Ls vs. ML file as a starting point.\n",
    "\n",
    "The below code generates and plots a polynom based on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def arbitrary_poly(params):\n",
    "    poly_model = lambda x: sum([p*(x**i) for i, p in enumerate(params)])\n",
    "    return poly_model\n",
    "\n",
    "# params: [theta_0, theta_1, ... , theta_n], where n = model order and theta_0 is bias \n",
    "true_params = [3,9,4]\n",
    "y_model = arbitrary_poly(true_params)\n",
    "\n",
    "# Plot true model\n",
    "x = np.linspace(start=-1, stop=1, num=20)\n",
    "plt.figure()\n",
    "plt.plot(x, y_model(x))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2\n",
    "\n",
    "The below function generates noise \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters for the type of noise-generating distribution.\n",
    "loc = 0           # location (mean) parameter \n",
    "scale = 1         # scaling (std dev) parameter\n",
    "magnitude = 1.2   # noise magnitude\n",
    "N = 200          # number of samples\n",
    "\n",
    "np.random.seed(123)  # Non-random generation between code executions. Comment out for true random\n",
    "\n",
    "# Generate data points\n",
    "range_low = -1\n",
    "range_high = 1\n",
    "u = np.sort(np.random.uniform(range_low,range_high,N))\n",
    "y_true = y_model(u)\n",
    "\n",
    "# Generate noise\n",
    "from scipy.stats import norm, laplace\n",
    "\n",
    "laplaceBeta = 1 # Input as the scale parameter in the Laplacian distribution\n",
    "\n",
    "normVariance = 1 # Input as the scale parameter in the normal distribution\n",
    "\n",
    "noiseLaplace = magnitude * np.random.laplace(loc, laplaceBeta, N)\n",
    "\n",
    "noiseGaussian  = magnitude * np.random.normal(loc, normVariance, N)\n",
    "\n",
    "noiseProbability = 0.5\n",
    "\n",
    "noiseLaplace = np.random.choice(noiseLaplace, int(N*noiseProbability))\n",
    "\n",
    "noiseGaussian = np.random.choice(noiseGaussian, int(N*(1-noiseProbability)))\n",
    "                          \n",
    "noise = np.concatenate((noiseLaplace, noiseGaussian))\n",
    "                       \n",
    "np.random.shuffle(noise)\n",
    "                       \n",
    "\n",
    "# Add noise to the generated data points - thus simulating measurement\n",
    "y = y_true + noise\n",
    "\n",
    "# Plot measured data\n",
    "plt.scatter(u, y, label=r\"Measured data\")\n",
    "u0 = np.linspace(-1, max(u), N)\n",
    "plt.plot(u0, y_model(u0), \"k\", alpha=0.3, lw=3, label=\"True model\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement noise generation from a chosen distribution\n",
    "Probability density functions (PDFs):\n",
    "\n",
    "Gaussian pdf: $P(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}$\n",
    "\n",
    "Laplacian pdf: $P(x) = \\frac{1}{2b}e^{-\\frac{|x-\\mu|}{b}}$\n",
    "\n",
    "Hyperparameters to adjust:\n",
    "- dist: \"laplace\" or \"gauss\" : the class of noise-generating distribution.\n",
    "- mu: The distribution's location parameter (mean value for Gauss).\n",
    "- sigma: The distribution's scaling parameter (std. for Gauss).\n",
    "- magnitude: The noise magnitude.\n",
    "- N: number of samples to generate for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares regression - LS\n",
    "### Given the sampled data we can estimate the underlying polynomial model using LS regression\n",
    "Solution to a least squares problem is given by the normal equation:  \n",
    "$\\hat{\\mathbf{\\theta}} = (\\mathbf{u}^T\\cdot \\mathbf{u})^{-1}(\\mathbf{u}^T\\cdot \\mathbf{y})$\n",
    "\n",
    "### Step 1 - rewrite the model in matrix form to get the data tensor u\n",
    "$y_{measured} = \\theta_0  + \\theta_1 \\cdot u^1 + ... + \\theta_n \\cdot u^n  + noise =   [1 \\; u^1 \\; .. \\; u^n] \\cdot [ \\theta_0 \\; \\theta_1 \\; .. \\; \\theta_n ] ^T + noise$\n",
    "\n",
    "$\\mathbf{u} = [1 \\; u^1 \\; .. \\; u^n]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix form\n",
    "u_tensor_0 = np.reshape(u,(N,1))\n",
    "print(f\"data u :\\n{u_tensor_0[0:5]} \\n\")\n",
    "\n",
    "ones_vec = np.ones((N,1))\n",
    "u_tensor = np.append(ones_vec, u_tensor_0, axis=1)\n",
    "\n",
    "for i in range(2,len(true_params)):\n",
    "    u_tensor = np.append(u_tensor, np.power(u_tensor_0, i) ,axis=1)\n",
    "\n",
    "print(f\"data tensor [1, u, u^2, ... , u^n] :\\n{u_tensor[0:5,:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2   \n",
    "\n",
    "calculate $(\\mathbf{u}^T \\cdot \\mathbf{u})^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_transpose_dot_u = np.dot(u_tensor.T,u_tensor)  # calculating dot product\n",
    "u_transpose_dot_u_inv = np.linalg.inv(u_transpose_dot_u) #calculating inverse\n",
    "print(u_transpose_dot_u_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3  \n",
    "\n",
    "calculate $(\\mathbf{u}^T \\cdot \\mathbf{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_transpose_dot_y = np.dot(u_tensor.T,y)  # calculating dot product\n",
    "print(u_transpose_dot_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 \n",
    "\n",
    "solve for $\\hat{\\mathbf{\\theta}} = (\\mathbf{u}^T\\cdot \\mathbf{u})^{-1}(\\mathbf{u}^T\\cdot \\mathbf{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LS_params = np.dot(u_transpose_dot_u_inv,u_transpose_dot_y)\n",
    "LS_params_rounded = [\"{:.2f}\".format(round(i, 2)) for i in LS_params.tolist()]\n",
    "print(f\"LS parameters:         {LS_params_rounded}\")\n",
    "print(f\"True model parameters: {true_params}\")\n",
    "\n",
    "diffParams = []\n",
    "for i in range(0, len(true_params)):\n",
    "    diffParams.append(float(true_params[i] - float(LS_params_rounded[i])))\n",
    "\n",
    "print(\"The differnence between the estimated theata and the real Theta is: \")\n",
    "\n",
    "print(diffParams)\n",
    "\n",
    "# Recreate model based on LS estimate:\n",
    "LS_params = LS_params.tolist()\n",
    "LS_estimate = arbitrary_poly(LS_params)\n",
    "\n",
    "# Plot true vs. estimated model\n",
    "plt.scatter(u, y, label=r\"Measured data $\\mathcal{N}(\\mu, \\sigma)$\")\n",
    "u0 = np.linspace(-1, max(u), N)\n",
    "plt.plot(u0, y_model(u0), \"k\", alpha=0.3, lw=3, label=\"True model\")\n",
    "plt.plot(u0, LS_estimate(u0), \"r--\",  lw=3, label=\"LS estimate\")\n",
    "#plt.xlim(0, 10)\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Letting alfa (noiseProbability) be 1, how does d depend on beta?\n",
    "\n",
    "\n",
    "First I change the parameters from the above simulation to match the ones given in the task:\n",
    "    \n",
    "    noiseProbability = 1\n",
    "    \n",
    "### Finding d with sigma = 100:\n",
    "\n",
    "The follwing code both make the noise, the LS solution and calculates the difference beteween the true measurements and LS.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDifference(alfa, sigma, beta):\n",
    "    \n",
    "    laplaceBeta = 1 # Input as the scale parameter in the Laplacian distribution\n",
    "\n",
    "    normVariance = sigma # Input as the scale parameter in the normal distribution\n",
    "\n",
    "    noiseLaplace = magnitude * np.random.laplace(loc, laplaceBeta, N)\n",
    "\n",
    "    noiseGaussian  = magnitude * np.random.normal(loc, normVariance, N)\n",
    "\n",
    "    noiseProbability = alfa\n",
    "\n",
    "    noiseLaplace = np.random.choice(noiseLaplace, int(N*noiseProbability))\n",
    "\n",
    "    noiseGaussian = np.random.choice(noiseGaussian, int(N*(1-noiseProbability)))\n",
    "\n",
    "    noise = np.concatenate((noiseLaplace, noiseGaussian))\n",
    "\n",
    "    np.random.shuffle(noise)\n",
    "\n",
    "\n",
    "    # Add noise to the generated data points - thus simulating measurement\n",
    "    y = y_true + noise\n",
    "\n",
    "    # Plot measured data\n",
    "    plt.scatter(u, y, label=r\"Measured data\")\n",
    "    u0 = np.linspace(-1, max(u), N)\n",
    "    plt.plot(u0, y_model(u0), \"k\", alpha=0.3, lw=3, label=\"True model\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\");\n",
    "    \n",
    "    # Matrix form\n",
    "    u_tensor_0 = np.reshape(u,(N,1))\n",
    "\n",
    "    ones_vec = np.ones((N,1))\n",
    "    u_tensor = np.append(ones_vec, u_tensor_0, axis=1)\n",
    "\n",
    "    for i in range(2,len(true_params)):\n",
    "        u_tensor = np.append(u_tensor, np.power(u_tensor_0, i) ,axis=1)\n",
    "\n",
    "    u_transpose_dot_u = np.dot(u_tensor.T,u_tensor)  # calculating dot product\n",
    "    u_transpose_dot_u_inv = np.linalg.inv(u_transpose_dot_u) #calculating inverse\n",
    "\n",
    "    u_transpose_dot_y = np.dot(u_tensor.T,y)  # calculating dot product\n",
    "\n",
    "    LS_params = np.dot(u_transpose_dot_u_inv,u_transpose_dot_y)\n",
    "    LS_params_rounded = [\"{:.2f}\".format(round(i, 2)) for i in LS_params.tolist()]\n",
    "    print(f\"LS parameters:         {LS_params_rounded}\")\n",
    "    print(f\"True model parameters: {true_params}\")\n",
    "\n",
    "    diffParams = []\n",
    "    for i in range(0, len(true_params)):\n",
    "        diffParams.append(format(str(float(true_params[i] - float(LS_params_rounded[i]))),\".4\"))\n",
    "\n",
    "    print(\"The differnence between the estimated theata and the real Theta is: \")\n",
    "\n",
    "    print(diffParams)\n",
    "\n",
    "    # Recreate model based on LS estimate:\n",
    "    LS_params = LS_params.tolist()\n",
    "    LS_estimate = arbitrary_poly(LS_params)\n",
    "\n",
    "    # Plot true vs. estimated model\n",
    "    plt.scatter(u, y, label=r\"Measured data $\\mathcal{N}(\\mu, \\sigma)$\")\n",
    "    u0 = np.linspace(-1, max(u), N)\n",
    "    plt.plot(u0, y_model(u0), \"k\", alpha=0.3, lw=3, label=\"True model\")\n",
    "    plt.plot(u0, LS_estimate(u0), \"r--\",  lw=3, label=\"LS estimate\")\n",
    "    #plt.xlim(0, 10)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\");\n",
    "\n",
    "calculateDifference(1, 100, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding d with sigma = 10:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateDifference(1, 10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding d with sigma = 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateDifference(1, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Letting alfa (noiseProbability) be 0, how does d depend on beta (laplaceBeta)?\n",
    "\n",
    "Doing the same as in the last task:\n",
    "\n",
    "### Finding d with beta = 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateDifference(0, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding d with beta = 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateDifference(0, 1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding d with beta = 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateDifference(0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}